install.packages("tidyverse")
library(tidyverse)
iris
summary(iris)
plot(iris)
plot(iris$Sepal.Length)
data = iris
summary(data)
plot(data)
plot(data$Sepal.Width~data&Sepal.Lenght)
dat = iris
summary(dat)
plot(data)
dataSetosa = data.class(dat$Species)
dr =  dat$Species
summary(dr)
plot(dr$setosa)
plot(dr$setosa)
dr = iris %>% group_by( Species) %>% summarise(Avg.Sepal.Ratio = mean(Sepal.Length/Sepal.Length), Avg.Sepal.Ratio = mean(Petal.Length/
Petal.Width ))
dr %>% gather(ratio, value,-Species)
plot(Petal.Length, Species)
dat$Species<- factor(dat$Species)
summary(dat)
str(dat)
dat.Setosa <- subset(dat, Species= "setosa")
plot(dat.Setosa)
plot(dat.Setosa)
boxplot(dat.Setosa)
plot(dat.Setosa)
str(dat.Setosa)
dat.Setosa<-droplevels(dat.Setosa)
str(dat.Setosa)
boxplot(dat.Setosa)
plot(dat.Setosa)
boxplot(dat.Setosa)
dat.versicolor <-droplevels(dat.vesicolor)
# species versicolor
dat.vesicolor <- subset(dat, Species="versicolor")
dat.versicolor <-droplevels(dat.vesicolor)
# species versicolor
dat.vesicolor <- subset(dat, Species="versicolor")
dat.vesicolor <-droplevels(dat.vesicolor)
str(dat.vesicolor)
dat.Setosa$Species <- subset(dat, Species= "setosa")
dat.Setosa$Species <- subset(dat, Species= "setosa")
dat.Setosa$Species<-droplevels(dat.Setosa$Species)
str(dat.Setosa)
boxplot(dat.Setosa)
levels(dat.Setosa)
dat = iris
dat <- iris
summary(dat)
plot(data)
dr = iris %>% group_by( Species) %>% summarise(Avg.Sepal.Ratio = mean(Sepal.Length/Sepal.Length), Avg.Sepal.Ratio = mean(Petal.Length/
Petal.Width ))
dr %>% gather(ratio, value,-Species)
dat$Species<- factor(dat$Species)
str(dat)
dat.Setosa$Species <- subset(dat, Species= "setosa")
dat.Setosa$Species<-droplevels(dat.Setosa$Species)
levels(dat.Setosa)
levels(dat.Setosa$Species)
dat$Species<- factor(dat$Species)
levels(dat$Species)
dat.Setosa$Species <- subset(dat, Species= "setosa")
levels(dat.Setosa$Species)
dat.Setosa$Species<-droplevels(dat.Setosa$Species)
levels(dat.Setosa$Species)
boxplot(dat.Setosa)
boxplot(Sepal.Lenght,dat.Setosa)
plot(Sepal.Lenght~Species,dat)
boxplot(Sepal.Lenght~Species,dat)
boxplot(dat$Sepal.Lenght~Species,dat)
boxplot(dat)
dat <- iris
summary(dat)
plot(data)
dat$Species<- factor(dat$Species)
levels(dat$Species)
boxplot(Sepal.Length~Species,dat)
boxplot(Sepal.With~Species,dat)
# petal
boxplot(Petal.Length~Species,dat)
boxplot(Petal.With~Species,dat)
boxplot(Petal.With~Species,dat, horizontal = True)
# 1 import iris data set
dat <- iris
# 2  summaries iris dataset
summary(dat)
# 3 plot iris dataset
plot(data)
dat$Species<- factor(dat$Species)
levels(dat$Species)
# sepal
boxplot(Sepal.Length~Species,dat)
# sepal
boxplot(Sepal.Length~Species,dat)
boxplot(Sepal.With~Species,dat)
# petal
boxplot(Petal.Length~Species,dat)
boxplot(Petal.With~Species,dat, horizontal = True)
dat.Setosa = subset(dat, Species=="setosa")
summary(dat.Setosa)
dat.Setosa <- subset(dat, Species=="setosa")
dat.Setosa$Species <-droplevels(dat.Setosa$Species)
summary(dat.Setosa)
plot(dat.Setosa)
plot(dat.Setosa$Sepal.Length,dat.Setosa$Sepal.Width)
plot(dat.Setosa$Sepal.Length,dat.Setosa$Petal.Length)
plot(dat.Setosa$Sepal.Length,dat.Setosa$Petal.Width)
plot(dat.Setosa)
plot(dat.Setosa$Petal.Length,dat.Setosa$Petal.Width)
dat.ver <- subset(dat, Species=="versicolora")
dat.ver$Species <-droplevels(dat.ver$Species)
summary(dat.ver)
plot(dat.ver)
dat.ver <- subset(dat, Species=="versicolor")
dat.ver$Species <-droplevels(dat.ver$Species)
summary(dat.ver)
plot(dat.ver)
plot(dat.ver$Sepal.Length,dat.ver$Sepal.Width)
plot(dat.ver$Sepal.Length,dat.ver$Petal.Length)
plot(dat.ver$Sepal.Length,dat.ver$Petal.Width)
plot(dat.ver$Petal.Length,dat.ver$Petal.Width)
dr = iris %>% group_by( Species) %>% summarise(Avg.Sepal.Ratio = mean(Sepal.Length/Sepal.Length), Avg.Sepal.Ratio = mean(Petal.Length/
Petal.Width ))
library(tidyverse)
geom_point(mapping = aes(x=iris$Sepal.Length,y=iris$Sepal.Width,color=Species)
ggplot(data=iris)+
geom_point(mapping = aes(x=iris$Sepal.Length,y=iris$Sepal.Width,color=Species))
ggplot(data=iris)+
geom_point(mapping = aes(x=iris$Sepal.Length,y=iris$Sepal.Width,color=iris$Species))
ggplot(data=iris)+
geom_point(mapping = aes(x=Sepal.Length,y=Sepal.Width,color=Species))
install.packages("tidyverse")
library(tidyverse)
install.packages("rpart")
library(rpart)
library(mrl)
install.packages("mlr")
library(mrl)
library(mlr)
library(mlr3)
install.packages("mlr3")
setwd("D:/University of Trieste/project/Sueza_project/Yemba")
install.packages("tm")
library(tm)
getwd()
archive_test <- file.path ("D:/University of Trieste/project/Sueza_project/Yemba", "methodo", "R", "ex")
archive_test
archive_test <- file.path ("D:/University of Trieste/project/Sueza_project/Yemba", "text")
archive_test
archive_test <- file.path ("D:/University of Trieste/project/Sueza_project/Yemba")
archive_test
dir (archive_test)
archive_test <- file.path ("D:\University of Trieste\project\Sueza_project\Data\Yemba")
archive_test <- file.path ("D:\University of Trieste\project\Sueza_project\Data\Yemba")
archive_test <- file.path ("D:/University of Trieste/project/Sueza_project/Data/Yemba")
archive_test
dir (archive_test)
archive_test <- file.path ("D:/University of Trieste/project/Sueza_project/Data/Yemba/corpus")
archive_test
dir (archive_test)
a  <-Corpus(DirSource(archive_test), readerControl = list(language="lat")) #specifies the exact folder where my text file(s) is for analysis with tm.
summary(a)
a  <-Corpus(DirSource(archive_test), readerControl = list(language="lat")) #specifies the exact folder where my text file(s) is for analysis with tm.
summary(a)
archive_test <- file.path ("D:/University of Trieste/project/Sueza_project/Data/Yemba/corpus")
archive_test
dir (archive_test)
pt = "D:/University of Trieste/project/Sueza_project/Data"
library(tidyverse)
library(tm)
pt = "D:/University of Trieste/project/Sueza_project/Data"
txt <- system.file(pt, package = "tm")
txt
ovid <- VCorpus(DirSource(txt, encoding = "UTF-8"), readerControl = list(language = "lat"))
pt = c("D:","University of Trieste","project", "Sueza_project", "Data")
txt <- system.file(pt, package = "tm")
txt
ovid <- VCorpus(DirSource(txt, encoding = "UTF-8"), readerControl = list(language = "lat"))
print(ovid)
inspect(ovid)
ovid
ovid[[2]]
ovid[[1]]
ovid[[0]]
ovid[[1]]
ovid[[3]]
ovid[[2]]
names(ovid)
archive_test <- file.path (pt)
archive_test
dir (archive_test)
pt = c("D:","University of Trieste","project", "Sueza_project", "Data","Yemba","corpus")
txt <- system.file(pt, package = "tm")
txt
ovid <- VCorpus(DirSource(txt, encoding = "UTF-8"), readerControl = list(language = "lat"))
print(ovid)
archive_test <- file.path (pt)
archive_test
dir (archive_test)
pt = c("D:","University of Trieste","project", "Sueza_project", "Data","Yemba","corpus")
archive_test <- file.path ("D:","University of Trieste","project", "Sueza_project", "Data","Yemba","corpus")
archive_test
dir (archive_test)
corpus.source <- Corpus(DirSource(archive_test))
show (corpus.source)
print (corpus.source)
inspect(corpus.source)
inspect(corpus.source[1])
corpus.source <- Corpus(DirSource(archive_test,encoding = "UTF-8"),readerControl = list(language = "lat"))
show (corpus.source)
print (corpus.source)
inspect(corpus.source)
inspect(corpus.source[1])
inspect(corpus.source[1])
inspect(corpus.source[2])
archive_test <- file.path ("D:","University of Trieste","project", "Sueza_project", "Data","Yemba","corpus")
archive_test
dir (archive_test)
corpus.source <- Corpus(DirSource(archive_test,encoding = "UTF-8"),readerControl = list(language = "lat"))
show (corpus.source)
print (corpus.source)
lapply(ovid[1:2], as.character)
lapply(corpus.source[1:2], as.character)
lapply(corpus.source[1:4], as.character)
names(corpus.source)
inspect(removeSparseTerms(corpus.source, 0.01))
# Extra whitespace is eliminated by:
reuters <- tm_map(corpus.source, stripWhitespace)
reuters
inspect(reuters[2])
reuters <- tm_map(reuters, removeWords, stopwords("lat"))
reuters <- tm_map(reuters, removeWords, stopwords("la"))
reuters <- tm_map(reuters, removeWords, stopwords("lat"))
inspect(reuters[1])
l<-inspect(reuters[1])
# Creating Term-Document Matrices
l
# Creating Term-Document Matrices
l[1]
# Creating Term-Document Matrices
dtm <- DocumentTermMatrix(reuters)
inspect(dtm)
findFreqTerms(dtm, 5)
findFreqTerms(dtm, 1)
findFreqTerms(dtm, 2)
findFreqTerms(dtm, 5)
findFreqTerms(dtm, 6)
findFreqTerms(dtm, 7)
findFreqTerms(dtm, 1)
findFreqTerms(dtm, 1)
wordcloud(dtm,
scale=c(5,0.1), rot.per=0.35,
min.freq=3, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(5,0.1), rot.per=0.35,
min.freq=3, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
# Wordclouds
library(wordcloud)
install.packages("wordcloud")
# Wordclouds
library(wordcloud)
wordcloud(reuters,
scale=c(5,0.1), rot.per=0.35,
min.freq=3, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(5,0.1), rot.per=0.35,
min.freq=1, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(5,0.1), rot.per=0.35,
min.freq=2, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(5,0.1), rot.per=0.35,
min.freq=2, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud (words (reuters[[2]]),
scale=c(5,0.1), rot.per=0.35,
min.freq=3, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(words (reuters[[3]]),
scale=c(5,0.1), rot.per=0.35,
min.freq=3, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud (words (reuters[[2]]),
scale=c(5,0.1), rot.per=0.35,
min.freq=1, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(words (reuters[[3]]),
scale=c(5,0.1), rot.per=0.35,
min.freq=1, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(words (reuters[[3]]),
scale=c(5,0.1), rot.per=0.35,
min.freq=1, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(5,0.1), rot.per=0.35,
min.freq=2, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(5,0.1), rot.per=0.35,
min.freq=5, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(5,0.1), rot.per=0.35,
min.freq=3, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
# Extra whitespace is eliminated by:
reuters <- tm_map(corpus.source, stripWhitespace)
getTokenizers(reuters)
removeWords(reuters, ",")
#removePunctuation()
#Enlever les ponctuations
reuters <- tm_map (reuters, removePunctuation, preserve_intra_word_dashes = TRUE)
# Creating Term-Document Matrices
dtm <- DocumentTermMatrix(reuters)
inspect(dtm)
findFreqTerms(dtm, 1)
findFreqTerms(dtm, 1)[1]
findFreqTerms(dtm, 1)[2]
findFreqTerms(dtm, 1)[289]
wordcloud(reuters,
scale=c(5,0.1), rot.per=0.35,
min.freq=3, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(5,0.1), rot.per=0.35,
min.freq=2, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(3,0.1), rot.per=0.35,
min.freq=2, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(3,0.1), rot.per=0.35,
min.freq=1, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(4,0.1), rot.per=0.35,
min.freq=1, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(4,0.1), rot.per=0.35,
min.freq=2, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(3,0.1), rot.per=0.35,
min.freq=2, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(reuters,
scale=c(3,0.1), rot.per=0.35,
min.freq=1, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
l <-findFreqTerms(dtm, 1)
str(l)
writeCorpus(reuters)
dataframe<-data.frame(text=unlist(sapply(l, `[`, "content")), stringsAsFactors=F)
write.csv(dataframe, "output.csv",encoding = "UTF-8")
write.csv(dataframe, "output.csv")
write.txt(dataframe, "output.txt")
write.table(l, file = "dict_yemba.txt", sep = "\t",
row.names = FALSE)
Encoding(l)
write.table(l, file = "dict_yemba.txt", sep = "\t",
row.names = FALSE)
write.table(l, file="chartest.txt", quote=F, col.names=F, row.names=F)
## The following should work on Windows - first grab and save your existing locale
print(Sys.getlocale(category = "LC_CTYPE"))
original_ctype <- Sys.getlocale(category = "LC_CTYPE")
## Switch to the appropriate local for the script
Sys.setlocale("LC_CTYPE","japanese")
## Now you can write your text out and have it look as you would expect
write.table(l, "chartest2.txt", quote = FALSE, col.names = FALSE,
row.names = FALSE, sep = "\t", fileEncoding = "UTF-8")
## ...and don't forget to switch back
Sys.setlocale("LC_CTYPE", original_ctype)
Encoding(l) #returns "UTF-8"
write.table(l, file="chartest.txt", quote=F, col.names=F, row.names=F)
## The following should work on Windows - first grab and save your existing locale
print(Sys.getlocale(category = "LC_CTYPE"))
original_ctype <- Sys.getlocale(category = "LC_CTYPE")
## Switch to the appropriate local for the script
Sys.setlocale("LC_CTYPE","lat")
## Switch to the appropriate local for the script
Sys.setlocale("LC_CTYPE","latin")
## Now you can write your text out and have it look as you would expect
write.table(l, "chartest2.txt", quote = FALSE, col.names = FALSE,
row.names = FALSE, sep = "\t", fileEncoding = "UTF-8")
## ...and don't forget to switch back
Sys.setlocale("LC_CTYPE", original_ctype)
library(tidyverse)
library(tm)
## http://edutechwiki.unige.ch/fr/Tutoriel_tm_text_mining_package
## https://cran.r-project.org/web/packages/tm/vignettes/tm.pdf
archive_test <- file.path ("D:","University of Trieste","project", "Sueza_project", "Data","Yemba","corpus")
archive_test
dir (archive_test)
corpus.source <- Corpus(DirSource(archive_test,encoding = "UTF-8"),readerControl = list(language = "lat"))
show (corpus.source)
## Inspection et utilisation de corpus
# print a short overview
print(corpus.source)
# show all
inspect(corpus.source)
# display the second document
inspect(corpus.source[2])
# afficher tous les textes
names(corpus.source)
lapply(corpus.source[1:4], as.character)
# Transformations
#Once we have a corpus we typically want to modify the documents in it, e.g., stemming, stopword removal,
#et cetera.
# Extra whitespace is eliminated by:
reuters <- tm_map(corpus.source, stripWhitespace)
#removePunctuation()
#Enlever les ponctuations
reuters <- tm_map (reuters, removePunctuation, preserve_intra_word_dashes = TRUE)
# Creating Term-Document Matrices
dtm <- DocumentTermMatrix(reuters)
inspect(dtm)
#  Imagine we want to find those terms that occur at least five times
l <-findFreqTerms(dtm, 1)
# Wordclouds
library(wordcloud)
wordcloud(reuters,
scale=c(3,0.1), rot.per=0.35,
min.freq=1, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud (words (reuters[[2]]),
scale=c(5,0.1), rot.per=0.35,
min.freq=1, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
wordcloud(words (reuters[[3]]),
scale=c(5,0.1), rot.per=0.35,
min.freq=1, use.r.layout=FALSE,
colors= brewer.pal(8,"Spectral")
)
writeCorpus(reuters)
dataframe<-data.frame(text=unlist(sapply(l, `[`, "content")), stringsAsFactors=F)
write.txt(dataframe, "output.txt")
Encoding(l)
write.table(l, file = "dict_yemba.txt", sep = "\t",
row.names = FALSE)
